{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Deep Learning - Lab 11\n","### Text Generation Using Transformers\n","### Story Generation from a Prompt\n","\n","-----------------------------------------------\n","\n","### Name: Faizaan Al Faisal\n","\n","----------------------------------------------\n","\n","This lab is regarding using a dataset of Writing Prompts, which consists of prompts followed by stories regarding those prompts, and using a Transformer Model (like GPT-2 from the Hugging Face Library) to create a model that can generate stories from prompts"]},{"cell_type":"markdown","metadata":{},"source":["-----------------------------------------------\n","\n","## Module Imports & Downloads\n","Importing all necessary modules and libraries."]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-12-12T16:35:40.965101Z","iopub.status.busy":"2023-12-12T16:35:40.964691Z","iopub.status.idle":"2023-12-12T16:35:55.666812Z","shell.execute_reply":"2023-12-12T16:35:55.665831Z","shell.execute_reply.started":"2023-12-12T16:35:40.965071Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["fatal: destination path 'transformers' already exists and is not an empty directory.\n","Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.35.2)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.4)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.24.3)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.8.8)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.0)\n","Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.1)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.12.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\n","mkdir: cannot create directory ‘/kaggle/working/combined/’: File exists\n"]}],"source":["!git clone https://github.com/huggingface/transformers\n","!pip install transformers\n","!mkdir \"/kaggle/working/combined/\""]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-12-12T16:35:55.668967Z","iopub.status.busy":"2023-12-12T16:35:55.668640Z","iopub.status.idle":"2023-12-12T16:35:55.675330Z","shell.execute_reply":"2023-12-12T16:35:55.674437Z","shell.execute_reply.started":"2023-12-12T16:35:55.668940Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from transformers import GPT2Tokenizer, GPT2LMHeadModel\n","from transformers.optimization import AdamW, get_linear_schedule_with_warmup\n","\n","import random\n","import numpy as np\n","import pandas as pd \n","import logging\n","from tqdm import tqdm\n","import math\n","import os"]},{"cell_type":"markdown","metadata":{},"source":["-----------------------------------------\n","\n","# Global Parameters\n","Using these parameters to modify overall command of the notebook. Modifies training parameters, dataset, etc."]},{"cell_type":"code","execution_count":75,"metadata":{"execution":{"iopub.execute_input":"2023-12-12T18:36:07.901396Z","iopub.status.busy":"2023-12-12T18:36:07.901007Z","iopub.status.idle":"2023-12-12T18:36:07.907694Z","shell.execute_reply":"2023-12-12T18:36:07.906757Z","shell.execute_reply.started":"2023-12-12T18:36:07.901364Z"},"trusted":true},"outputs":[],"source":["# randomization seed\n","np.random.seed(100)\n","\n","# model/training parameters\n","model_name = \"gpt2\"\n","# model_name = \"distilgpt2\"\n","max_len = 512\n","batch_size = 4\n","epochs = 1\n","warmup = 0.1\n","weight_decay = 0.01\n","lr = 5e-5\n","adam_eps = 1e-8\n","\n","# dataset\n","sample_percent = 15\n","file_dir = \"/kaggle/input/writing-prompts/writingPrompts/\"\n","combined_dir = \"/kaggle/working/combined/\""]},{"cell_type":"markdown","metadata":{},"source":["-----------------------------------------------\n","\n","## Data Preprocessing\n","First, sample the original dataset. The datasets provided are huge and are not being properly converted to dataset objects due to their size and resource limitations.\n","\n","Next combine the source and target files into one combined set, and store in /kaggle/working/combined for sake of training model more easily.\n","\n","Now, data is stored like \"prompt goes here [ENDPROMPT] story goes here \\n\". This is the format of inputs/outputs that GPT2 model expects and works best with, and so is our preferred approach."]},{"cell_type":"code","execution_count":76,"metadata":{"execution":{"iopub.execute_input":"2023-12-12T18:36:11.192703Z","iopub.status.busy":"2023-12-12T18:36:11.192026Z","iopub.status.idle":"2023-12-12T18:36:20.001199Z","shell.execute_reply":"2023-12-12T18:36:20.000181Z","shell.execute_reply.started":"2023-12-12T18:36:11.192668Z"},"trusted":true},"outputs":[],"source":["# decrease the size of sets by sampling, then combine source/target into one file\n","# target is appended to source after [ENDPROMPT] token, newline is added at end of combined\n","def sample_and_combine(sample_percent, max_len, file_dir, combined_dir, name):\n","    with open(file_dir + name + \".wp_source\", \"r\", encoding=\"utf-8\") as f:\n","        source = f.readlines()\n","    with open(file_dir + name + \".wp_target\", \"r\", encoding=\"utf-8\") as f:\n","        target = f.readlines()\n","    \n","    # ensure same number of items in source and target\n","    assert len(source) == len(target)\n","    # calculate number of samples\n","    samples = int(len(source) * (sample_percent / 100))\n","    # randomly select indices from amount sampled\n","    indices = random.sample(range(len(source)), samples)\n","    # shorten the lists to only those in samples\n","    source = [source[i] for i in indices]\n","    target = [target[i] for i in indices]\n","    \n","    # combine the source and target with endprompt token in between\n","    combined = [source[i].rstrip()+ \" <ENDPROMPT> \" + \" \".join(target[i].split()[0:max_len]) for i in range(len(target))]\n","    text = []\n","    with open(combined_dir + name + \".wp_combined\", \"w\") as f:\n","        for x in combined:\n","            f.write(x.strip() + \"\\n\")\n","            text.append(x)\n","    return text\n","\n","def clean_data(s):\n","    punct_chars = '!,.:;?'\n","    for p in punct_chars:\n","        s = s.replace(' ' + p, p)\n","    contractions = [\"n't\", \"'s\", \"' s\", \"'re\", \"'ve\", \"' ve\", \"'ll\", \"'am\", \"' m\", \"'m\", \"'ve\", \"'s\"]\n","    for c in contractions:\n","        s = s.replace(' ' + c, c)\n","    s = s.replace('<newline>', '\\n')\n","    return s\n","\n","# generate combined files for the datasets\n","train_data = sample_and_combine(sample_percent, max_len, file_dir, combined_dir, \"train\")\n","valid_data = sample_and_combine(sample_percent, max_len, file_dir, combined_dir, \"valid\")\n","test_data = sample_and_combine(sample_percent, max_len, file_dir, combined_dir, \"test\")\n","\n","# clean the data slightly by better dealing with contractions and weird characters\n","train_data = list(map(clean_data, train_data))\n","valid_data = list(map(clean_data, valid_data))\n","test_data  = list(map(clean_data, test_data))"]},{"cell_type":"code","execution_count":77,"metadata":{"execution":{"iopub.execute_input":"2023-12-12T18:36:33.094750Z","iopub.status.busy":"2023-12-12T18:36:33.093630Z","iopub.status.idle":"2023-12-12T18:36:33.101582Z","shell.execute_reply":"2023-12-12T18:36:33.100612Z","shell.execute_reply.started":"2023-12-12T18:36:33.094700Z"},"trusted":true},"outputs":[{"data":{"text/plain":["\"[ IP ] Freelance Death Wizard <ENDPROMPT> The blue ink on my arm was fading fast but I had memorized it. \\n \\n `` Mercenary Magic: Death's Door Pub '' \\n \\n I hurried through the streets, having waited until almost midnight. A cold rain fell against my coat, pulled up tight to ward off the November chill. The cobbled streets were mostly empty but for the odd wanderer or drunk. None payed me any attention. \\n \\n Rounding a corner I saw it. Unmistakable. A black plank of wood with a bright blue eye emblazoned on it hung from two thick black chains. The street lights were out along the whole street except for the two in front of the pub. It was an eerie sight, bright yellow flickering lights against a nearly pitch black backdrop. \\n \\n The building itself was wooden, with two massive windows with iron frames jutting out into the street. There was yellow light escaping through tiny holes and gaps in the thick black curtains drawn on the inside of the windows. \\n \\n Glancing back and forth, I quickly made my way across the street and down towards the pub. A heavy wrought iron handle gave way under my hands, slick with the cold rain, and brought me into an anteroom. There were coat hooks lining the confined space, with only a few occupied pegs. I shook off my coat and placed it up, not wanting to draw attention. \\n \\n The inside of the pub was old fashioned of sorts, a polished length of red wood for the bar lined with heavy wooden stools. The bartender was a thin man with a ragged scar running down the length of his face to his neck. From the deceptively high ceiling hung down iron chandeliers topped with candles, dusty bookcases and cabinets lined the exterior wall while wooden tables dotted the floor space. \\n \\n `` Sit where you like. '' \\n \\n The bartender said it while polishing out the inside of a glass with a filthy looking rag. Small comforts to see such familiar actions. \\n \\n There were only six more occupants. \\n \\n Two thick necked men sitting by one of the windows that were several pints deep into a drinking match. \\n \\n A man and woman in black cloaks reading from one of the bookshelves in two thickly padded chairs. \\n \\n A City Sergeant at the bar, in uniform and uncaring. \\n \\n And a figure with his feet up on a table mounted with books and a melting candle, apparently asleep. He wore a deep red vest with a dark black overcoat hanging off the empty chair opposite him. \\n \\n I rolled up my sleeve and looked down. \\n \\n `` Welcome. '' \\n \\n The letters flashed before\""]},"execution_count":77,"metadata":{},"output_type":"execute_result"}],"source":["train_data[1]"]},{"cell_type":"markdown","metadata":{},"source":["------------------------------------------------\n","\n","# Data Formatting\n","Data needs to be properly processed to be acceptable by the GPT-2 Models. First, we must tokenize it using the GPT2 Tokenizer objects from the HF-Transformers library.\n","\n","Next, tokenize the data of all of the sampled/combined files.\n","\n","Then, GPT2 model needs objects with three categories: \"input_ids\", \"attention_mask\", and \"labels\". The tokenizer generates input_ids and attention_mask, but the labels need to be set.\n","\n","Finally, since we are working with the PyTorch side of the Hugging Face Transformers, we must create a custom dataset and dataloader to feed the data to the model properly"]},{"cell_type":"code","execution_count":78,"metadata":{"execution":{"iopub.execute_input":"2023-12-12T18:37:13.898858Z","iopub.status.busy":"2023-12-12T18:37:13.898462Z","iopub.status.idle":"2023-12-12T18:40:17.577033Z","shell.execute_reply":"2023-12-12T18:40:17.575907Z","shell.execute_reply.started":"2023-12-12T18:37:13.898822Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fc017fb9db8c4ebb82faf9c059a453cb","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d099917e955d45219a6d1abfe622bfa3","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7308cfef46ae4677b125a26e1f49db65","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3a2cd8dcd4b4400eb57d87fecc5f0241","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# create gpt2 tokenizer object and set padding token\n","tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n","tokenizer.pad_token = tokenizer.eos_token\n","tokenizer.pad_token_id = tokenizer.eos_token_id\n","\n","# tokenize the 3 datasets, generates 2d list of input_ids & attention_mask\n","tokenized_train = tokenizer(train_data, padding=True,truncation=True,max_length=max_len)\n","tokenized_valid = tokenizer(valid_data, padding=True,truncation=True,max_length=max_len)\n","tokenized_test  = tokenizer(test_data,  padding=True,truncation=True,max_length=max_len)"]},{"cell_type":"code","execution_count":79,"metadata":{"execution":{"iopub.execute_input":"2023-12-12T18:40:17.579294Z","iopub.status.busy":"2023-12-12T18:40:17.579002Z","iopub.status.idle":"2023-12-12T18:40:18.685736Z","shell.execute_reply":"2023-12-12T18:40:18.684936Z","shell.execute_reply.started":"2023-12-12T18:40:17.579269Z"},"trusted":true},"outputs":[],"source":["# create labels for the data\n","def generate_labels(inputs):\n","    labels=[]\n","    for ids, attention in zip(inputs['input_ids'],inputs['attention_mask']):\n","        label = ids.copy()\n","        real_length = sum(attention)\n","        padding_length = len(attention) - real_length\n","        label[:] = label[:real_length] + [-100] * padding_length\n","        labels.append(label)\n","    \n","    inputs['labels']=labels\n","    \n","generate_labels(tokenized_train)\n","generate_labels(tokenized_valid)\n","generate_labels(tokenized_test)"]},{"cell_type":"markdown","metadata":{},"source":["## PyTorch Data Handling\n","Creating a custom Dataset class alongside creating the dataloader objects to fed information to the model during eval and training."]},{"cell_type":"code","execution_count":80,"metadata":{"execution":{"iopub.execute_input":"2023-12-12T18:40:55.947575Z","iopub.status.busy":"2023-12-12T18:40:55.947202Z","iopub.status.idle":"2023-12-12T18:40:55.954500Z","shell.execute_reply":"2023-12-12T18:40:55.953539Z","shell.execute_reply.started":"2023-12-12T18:40:55.947544Z"},"trusted":true},"outputs":[],"source":["class LabDataset:\n","    def __init__(self, inputs):\n","        self.ids = inputs['input_ids']\n","        self.attention = inputs['attention_mask']\n","        self.labels = inputs['labels']\n","\n","    def __len__(self):\n","        return len(self.ids)\n","\n","    def __getitem__(self, idx):\n","\n","        return  [\n","                    torch.tensor(self.ids[idx], dtype=torch.long),\n","                    torch.tensor(self.attention[idx], dtype=torch.long),\n","                    torch.tensor(self.labels[idx], dtype=torch.long)\n","                ]"]},{"cell_type":"code","execution_count":81,"metadata":{"execution":{"iopub.execute_input":"2023-12-12T18:41:04.061025Z","iopub.status.busy":"2023-12-12T18:41:04.060656Z","iopub.status.idle":"2023-12-12T18:41:04.188057Z","shell.execute_reply":"2023-12-12T18:41:04.187145Z","shell.execute_reply.started":"2023-12-12T18:41:04.060994Z"},"trusted":true},"outputs":[],"source":["# creating dataset objects\n","train_dataset = LabDataset(tokenized_train)\n","valid_dataset = LabDataset(tokenized_valid)\n","test_dataset  = LabDataset(tokenized_test)\n","\n","# creating dataloader objects\n","train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n","valid_loader = torch.utils.data.DataLoader(valid_dataset, shuffle=True, batch_size=batch_size)\n","test_loader = torch.utils.data.DataLoader(test_dataset, shuffle=True, batch_size=batch_size)"]},{"cell_type":"markdown","metadata":{},"source":["----------------------------------------------\n","\n","# Modular Functions\n","Creating generic functions to train and evaluate the model for one epoch. This allows the code to be more modular and easy to manipulate."]},{"cell_type":"code","execution_count":82,"metadata":{"execution":{"iopub.execute_input":"2023-12-12T18:41:08.080090Z","iopub.status.busy":"2023-12-12T18:41:08.079697Z","iopub.status.idle":"2023-12-12T18:41:08.090038Z","shell.execute_reply":"2023-12-12T18:41:08.089115Z","shell.execute_reply.started":"2023-12-12T18:41:08.080058Z"},"trusted":true},"outputs":[],"source":["# run one epoch of training\n","def model_train(model, optimizer, scheduler, dataloader):\n","    model.train()\n","    loss = []\n","    perplexity_vals = []\n","    \n","    for inputs in tqdm(dataloader, desc=\"Training\"):\n","        # break inputs into all parts and put all on devices\n","        input_ids, attention, labels = inputs\n","        input_ids = input_ids.to('cuda')\n","        attention = attention.to('cuda')\n","        labels = labels.to('cuda')\n","        \n","        # get outputs\n","        optimizer.zero_grad()\n","        output = model(input_ids=input_ids, attention_mask=attention, labels=labels)\n","        # calculate loss\n","        logits = output.logits\n","        batch_loss = nn.functional.cross_entropy(logits.view(-1, logits.size(-1)), labels.view(-1))\n","        # backward prop + steps\n","        batch_loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","        # store values for calculation of loss + perplexity\n","        loss.append(batch_loss.cpu().item())\n","        perplexity_vals.append(math.exp(batch_loss.cpu().item()))\n","\n","        del batch_loss\n","\n","    return  {\n","                \"Loss\": np.mean(loss),\n","                \"Perplexity\": np.mean(perplexity_vals)\n","            }"]},{"cell_type":"code","execution_count":83,"metadata":{"execution":{"iopub.execute_input":"2023-12-12T18:41:10.568473Z","iopub.status.busy":"2023-12-12T18:41:10.567745Z","iopub.status.idle":"2023-12-12T18:41:10.576455Z","shell.execute_reply":"2023-12-12T18:41:10.575318Z","shell.execute_reply.started":"2023-12-12T18:41:10.568437Z"},"trusted":true},"outputs":[],"source":["# run one epoch of validation or testing\n","def model_eval(model, dataloader, testing=False):\n","    model.eval()\n","    eval_loss = []\n","\n","    desc = \"Testing\" if testing else \"Validation\"\n","    for inputs in tqdm(dataloader, desc=desc):\n","        input_ids, attention, labels = inputs\n","        input_ids = input_ids.to('cuda')\n","        attention = attention.to('cuda')\n","        labels = labels.to('cuda')\n","        \n","        with torch.no_grad():\n","            output = model(input_ids=input_ids, attention_mask=attention, labels=labels)\n","            logits = output.logits\n","            batch_loss = nn.functional.cross_entropy(logits.view(-1, logits.size(-1)), labels.view(-1))\n","\n","        eval_loss.append(batch_loss.cpu().item())\n","        del batch_loss\n","\n","    average_loss = np.mean(eval_loss)\n","    perplexity = math.exp(average_loss)\n","    \n","    return  {\n","                \"Loss\": average_loss,\n","                \"Perplexity\": perplexity,\n","            }"]},{"cell_type":"code","execution_count":84,"metadata":{"execution":{"iopub.execute_input":"2023-12-12T18:41:17.456125Z","iopub.status.busy":"2023-12-12T18:41:17.455747Z","iopub.status.idle":"2023-12-12T18:41:17.466517Z","shell.execute_reply":"2023-12-12T18:41:17.465577Z","shell.execute_reply.started":"2023-12-12T18:41:17.456097Z"},"trusted":true},"outputs":[],"source":["def generate_stories(model, tokenizer, prompt, target, k=0, p=0.9, output_length=300, temperature=0.9, \n","                   num_return_sequences=3, max_new_tokens=0, repetition_penalty=1.0):\n","    \n","    print(\"\\n  Prompt \\n=====================================\\n\")\n","    print(prompt + \"\\n\")\n","    print(\"\\n\\n  Target Story \\n=====================================\\n\")\n","    print(target + \"\\n\")\n","    \n","    tokenizer.pad_token_id = tokenizer.eos_token_id\n","    tokenizer.pad_token = tokenizer.eos_token\n","    encoded_prompt = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\")\n","    \n","    attention_mask = torch.ones_like(encoded_prompt)\n","\n","    # Access the underlying model if using DataParallel\n","    model = model.module if isinstance(model, torch.nn.DataParallel) else model\n","    model = model.to('cpu')\n","    model.eval()\n","\n","    output_sequences = model.generate(\n","        input_ids=encoded_prompt,\n","        attention_mask=attention_mask,\n","        max_length=output_length,\n","        temperature=temperature,\n","        top_k=k,\n","        top_p=p,\n","        repetition_penalty=repetition_penalty,\n","        do_sample=True,\n","        num_return_sequences=num_return_sequences,\n","#         max_new_tokens=max_new_tokens,\n","    )\n","\n","    if len(output_sequences.shape) > 2:\n","        output_sequences.squeeze_()\n","\n","    for idx, generated_sequence in enumerate(output_sequences):\n","        print(f\"\\n\\n Generated Sequence {idx + 1} \\n=====================================\\n\")\n","        generated_sequence = generated_sequence.tolist()\n","        text = tokenizer.decode(generated_sequence, clean_up_tokenization_spaces=True)\n","        text = text[: text.find(tokenizer.eos_token)]\n","        print(text)\n","        \n","    model = nn.DataParallel(model.cuda())\n"]},{"cell_type":"markdown","metadata":{},"source":["-----------------------------------------------\n","\n","# Model Training\n","Now we must fine tune the model with all that we have done so far"]},{"cell_type":"code","execution_count":85,"metadata":{"execution":{"iopub.execute_input":"2023-12-12T18:41:21.611923Z","iopub.status.busy":"2023-12-12T18:41:21.611162Z","iopub.status.idle":"2023-12-12T18:41:26.165819Z","shell.execute_reply":"2023-12-12T18:41:26.165066Z","shell.execute_reply.started":"2023-12-12T18:41:21.611888Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7b5ec32dadbf48999bb2db0cd8b71c09","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1f6cb92b296146e79d5b7528127ed456","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# model creation\n","model = GPT2LMHeadModel.from_pretrained(model_name)\n","model = model.to(\"cuda\")\n","\n","# model set to use both GPUs\n","model = nn.DataParallel(model)\n","\n","# optimizer\n","optimizer = torch.optim.AdamW(model.parameters(), lr=lr, eps=adam_eps,weight_decay=weight_decay)\n","\n","# lr scheduler\n","scheduler = get_linear_schedule_with_warmup(\n","    optimizer,\n","    num_warmup_steps=len(train_loader) * epochs * warmup,\n","    num_training_steps=len(train_loader) * epochs\n",")"]},{"cell_type":"code","execution_count":86,"metadata":{"execution":{"iopub.execute_input":"2023-12-12T18:41:33.402494Z","iopub.status.busy":"2023-12-12T18:41:33.401654Z","iopub.status.idle":"2023-12-12T18:43:12.697596Z","shell.execute_reply":"2023-12-12T18:43:12.696619Z","shell.execute_reply.started":"2023-12-12T18:41:33.402456Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Evaluating Model on Testing Set Before Training:\n","=====================================\n","\n"]},{"name":"stderr","output_type":"stream","text":["Testing:   0%|          | 0/568 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","Testing: 100%|██████████| 568/568 [01:39<00:00,  5.72it/s]"]},{"name":"stdout","output_type":"stream","text":["Loss before Fine-Tuning: 9.25445453717675\n","Perplexity before Fine-Tuning: 10451.016623188278\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# eval on test set before fine-tuning\n","print(f\"Evaluating Model on Testing Set Before Training:\\n=====================================\\n\")\n","test_results = model_eval(model, test_loader, testing=True)\n","print(f\"Loss before Fine-Tuning: {test_results['Loss']}\")\n","print(f\"Perplexity before Fine-Tuning: {test_results['Perplexity']}\")"]},{"cell_type":"code","execution_count":90,"metadata":{"execution":{"iopub.execute_input":"2023-12-12T18:45:57.668322Z","iopub.status.busy":"2023-12-12T18:45:57.667607Z","iopub.status.idle":"2023-12-12T18:46:37.054597Z","shell.execute_reply":"2023-12-12T18:46:37.053656Z","shell.execute_reply.started":"2023-12-12T18:45:57.668288Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","  Prompt \n","=====================================\n","\n","[ WP ] You've spent the last two years living as a dog-like pet to an alien family who abducted/adopted/rescued. One day they come home with a new human... \n","\n","\n","\n","  Target Story \n","=====================================\n","\n"," `` Come on Liz, time to eat, then we'll go for a walk. '' \n"," \n"," I stretched from my cot, blinked at the creature staring at me holding a backpack with a leash. This again... Well, at least I wasn't a zoo exhibit. `` Morning, '' I grumbled, stretching and groaning. My vocal chords were unable to make many of the sounds that this strance species could, but I could communicate a little. `` Too early, '' I whined. My family, if i could call them that, were all early risers. Before... before here I never got up before the sun was up. Here, the sun wasn't even peeking at the horizon. `` Sleep more. '' \n"," \n"," `` No little one, we have to go for a walk. You're too lazy when I don't walk you, and you don't want the human catchers to get you. Then you can watch TV all day and sleep if you want. '' \n"," \n"," I frowned. No amount of complaining worked around here. `` Fine. Dress, pee, then food. '' \n"," \n"," `` Very good. You're bowl will be in it's place. I made you some Earth food today, phan-chakes ''. `` Pancakes! Yay! '' \n"," \n"," `` Yes, those. '' The female left the room and I put on some sweats and a t-shirt. I saw no need to pretty myself up, I was the friggin pet for Christ sake! \n"," \n"," I wandered into the serving room and immediatly my eyes opened wide. Another human! A man! What the hell was he doing here? '' \n"," \n"," `` Why he here? I pet, no him! '' \n"," \n"," `` He's the newest member of our family. He's a few years younger than you, so be nice to him. '' \n"," \n"," `` Huh! '' I searched the newcomer, and he met my eyes. I saw a bit of fear. `` You... What's your name! '' \n"," \n"," `` Espanol? '' He asked. \n"," \n"," Shit. Wellllll... `` Uh... como se llamo? '' \n"," \n"," `` Jose. Tu? '' \n"," \n"," `` Amanda. I'm American. '' \n"," \n"," `` I'm from Spain. I don't know where this is, or anything. Are they mean? Will they hurt me? '' \n"," \n"," `` Nah, but you 'd better get used to walking on a leash. Human catchers can be cruel. '' \n"," \n"," Jose... how lucky of me to get a new human, a male at that... my\n","\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n"," Generated Sequence 1 \n","=====================================\n","\n","[ WP ] You've spent the last two years living as a dog-like pet to an alien family who abducted/adopted/rescued. One day they come home with a new human...  We assume you, the adoptive parent, is upset. You find your \"home\" so the parents of the new human who has escaped that shack.  A therapist says this human has a \"special relationship with you. It's as if they have come from the dead, with no memories. The human's mother went through a terrible mental breakdown, but has come back to life, with you, and your love and care. So you're so motivated to find her, you go up into the house. The therapist takes care of your home, and we spend the next three years living with her. They help you realize that you love them as you know them.\"\n","Deist Designs, 2010-2011\n","\"The first people we tried, it was just a fun thing. The first time we came to San Francisco was a year or so ago. We came to San Francisco for an event. We bought some very good wooden bicycles and everything. When the issue came up, we all assumed it was a prank. They basically turned it into a child pornography raid. They set up a little computer database of addresses and IP addresses of every person who calls that number on the Internet and gave us information about the people who had contacted us in San Francisco. We made a deposit, we did a sweep. We called this guy we know, who he called dad and we used him to get access to the child porn database. All this in just a couple of weeks. It was a long time until I saw the pictures. It was like I was walking in a dark forest, I couldn't believe it. We were convinced that this was real and that we'd found this new face of our animal, who I thought would be a good fit. My grandmother had an actual pet, an Asian male dog named Kangaroo, and she didn't look like what we were looking for. I was devastated that it was my human, who's been stolen.\n","\"It was a hard day in the day,\" Deist told me. \"One of the earliest parts of the '09 project was the reunion. It took about three weeks. We stayed at an apartment in Northridge for a week, and then I fell in love with the house we were staying in. All the great people who came up to us asked for help wit\n","\n","\n"," Generated Sequence 2 \n","=====================================\n","\n","[ WP ] You've spent the last two years living as a dog-like pet to an alien family who abducted/adopted/rescued. One day they come home with a new human...  A living food source and a companion, and you're a happy person... but you've been abandoned. There are hundreds of them now, every year for two weeks to find a new place to stay. You end up running across one in one of your friends' houses... a bookends from your poor little life. You call the police, but you don't have much you can do. You spend the day on a floating island, until you stumble across something you'd rather not be there with. You start a new life, but in three years you're abandoned for nothing. Your parents call the police. In a few months you find yourself in the clutches of a hardened criminal. The gang members are known as the KLUN forces and have amassed a massive following. You fall in with them. You have to pay their bail for the man who killed you. You're told that you were the victim of a brutal and strange crime, a savage retribution for your inability to resist. The KLUN forces are deposed and you're placed in the Gulag. No one will talk about what happened to you, except for the KLUN who claim that they brought you here for the purpose of catching you. You spend your days in jail, free from your family and friends, until the law is written. But, one day you discover yourself at the centre of a gang of muggles who set you up at the Gulag, and recruit you as their leader. Then you spend six years in jail and two years in the Gulag in your forced labor. I want to turn the page on your life and get you back on your feet.  And for that I can't offer any other reward.  I need the money to pay back the money I owe them. The war against the KLUN forces is over.  One last desperate campaign in the Desert to get back to the more civilized world. I believe that this is the last time I'll ever be able to visit one of those strongholds, and get my life back on track. I'm doing a book called The Manchurian Candidate. A full introduction to the character of the man responsible for the Gulag murders, for getting you back on track with your humanity. For the first half of this book you get some extra stuf\n","\n","\n"," Generated Sequence 3 \n","=====================================\n","\n","[ WP ] You've spent the last two years living as a dog-like pet to an alien family who abducted/adopted/rescued. One day they come home with a new human...  And you're a dog.  Are you okay? So how do you feel?  Do you want to stay?  How do you think about the problem?  As an adult, what did you do right?  How do you feel about the world today?\n","\"\n","I couldn't write and couldn't change my language, so I couldn't ask for help.  And that's how I felt.  This day is the day I'm going to say yes.  We're going to get on board.  I don't know what to say.  If I don't want to get along with them, what do you say?  I want to stay happy.  I want to love.  I want to find happiness.  I'm going to be okay.  I'm going to be fine.  That's why I'll get back to you.  To give you a hug and show you how much I love you.\"\n","- Neal Stephenson\n","This is just as true of something like Lord of the Rings as it is about a dog.  To be clear, the troll doesn't give a damn about Tolkien, nor does he need to.  Just like the cat.  His name comes from the Russian term \"kodražki.\"  No I'm not being sarcastic, nor am I snarky.  Nor am I being condescending.  I'm just saying I'm a true fan.  I think that he has about as much ability to know or empathize with readers as any other character in the world.  So that means that you should read Lord of the Rings and know more about him.  If you read the book, please read what he wrote for you.  You'll need to know more about him for the rest of your life to actually enjoy his adventures.  Now, I'm not saying that reading the book would make you cry.  I'm saying that as you progress through this story you will.  But that is why it's so important to read them.  I want to give you a feeling for the world.  You're going to see something tha\n"]}],"source":["# generate some stories before and after training\n","token = \"<ENDPROMPT>\"\n","chosen = 5\n","prompt = test_data[chosen][ : test_data[chosen].find(token)]\n","story = test_data[chosen][test_data[chosen].find(token)+len(token) : ]\n","generate_stories(model, tokenizer, prompt, story)"]},{"cell_type":"code","execution_count":91,"metadata":{"execution":{"iopub.execute_input":"2023-12-12T18:47:17.112111Z","iopub.status.busy":"2023-12-12T18:47:17.111319Z","iopub.status.idle":"2023-12-12T20:11:45.073569Z","shell.execute_reply":"2023-12-12T20:11:45.072600Z","shell.execute_reply.started":"2023-12-12T18:47:17.112076Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1:\n","=====================================\n"," Training:\n","\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 10223/10223 [1:22:45<00:00,  2.06it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 0.06648484685055595\n","Perplexity: 16.567529318647402\n","=====================================\n"," Validation:\n","\n"]},{"name":"stderr","output_type":"stream","text":["Validation: 100%|██████████| 586/586 [01:42<00:00,  5.71it/s]"]},{"name":"stdout","output_type":"stream","text":["Loss: 0.06648484685055595\n","Perplexity: 16.567529318647402\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# fine tune the model\n","for epoch in range(epochs):\n","\n","    print(f\"Epoch {epoch + 1}:\\n=====================================\\n Training:\\n\")\n","    train_metrics = model_train(model, optimizer, scheduler, train_loader)\n","    print(f\"Loss: {train_metrics['Loss']}\")\n","    print(f\"Perplexity: {train_metrics['Perplexity']}\")\n","\n","    \n","    print(f\"=====================================\\n Validation:\\n\")\n","    valid_metrics = model_eval(model, valid_loader)    \n","    print(f\"Loss: {train_metrics['Loss']}\")\n","    print(f\"Perplexity: {train_metrics['Perplexity']}\")"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2023-12-12T17:30:14.188137Z","iopub.status.busy":"2023-12-12T17:30:14.187777Z","iopub.status.idle":"2023-12-12T17:30:57.719482Z","shell.execute_reply":"2023-12-12T17:30:57.718589Z","shell.execute_reply.started":"2023-12-12T17:30:14.188110Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Evaluating Model on Testing Set after Fine-Tuning:\n","=====================================\n","\n"]},{"name":"stderr","output_type":"stream","text":["Testing: 100%|██████████| 379/379 [00:43<00:00,  8.71it/s]"]},{"name":"stdout","output_type":"stream","text":["Loss after Fine-Tuning: 0.0003140458930951868\n","Perplexity after Fine-Tuning: 1.0003140952106693\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# evaluate the model again after fine-tuning\n","print(f\"Evaluating Model on Testing Set after Fine-Tuning:\\n=====================================\\n\")\n","test_results = model_eval(model, test_loader, testing=True)\n","print(f\"Loss after Fine-Tuning: {test_results['Loss']}\")\n","print(f\"Perplexity after Fine-Tuning: {test_results['Perplexity']}\")"]},{"cell_type":"code","execution_count":89,"metadata":{"execution":{"iopub.execute_input":"2023-12-12T18:44:39.182425Z","iopub.status.busy":"2023-12-12T18:44:39.181638Z","iopub.status.idle":"2023-12-12T18:45:19.558058Z","shell.execute_reply":"2023-12-12T18:45:19.557101Z","shell.execute_reply.started":"2023-12-12T18:44:39.182389Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["72\n","\n","  Prompt \n","=====================================\n","\n","[ WP ] `` I'm sorry, but the thing you were looking for is sold out. '' \n","\n","\n","\n","  Target Story \n","=====================================\n","\n"," “ I ’ m sorry, but the thing you were looking for is sold out. ” The government agent on the other end of the phone had said the sentence softly, yet firmly. She said nothing more, careful not to waste her resources to reason with a desperate, dying man. \n"," \n"," It couldn ’ t be. There was just no way. When the product first emerged on the market, it was a satire. I purchased a few cans, as did all my friends. We were amused. Who knew, that it would actually catch on. It remained on sale, spreading, like wildfire. People purchased the cans as jokes, to show their friends, to silently protest. The government neither condemned nor encouraged them initially. It knew that attacking the product would give it power. \n"," \n"," As time went on, the pollution spread. Smog that could previously be blocked out by mere masks could now permeate even the best clothing. A fifteen minute walk outside required a ten minute shower to scrub out the dirt and grime. Then the next winter came, a colder one than most. The polar vortex, a term so foreign just half a decade before, was swinging around again. Temperatures dropped continuously, and the heaters in the large city of 25 million burned furiously. After several days, the sun, which during the best of days shredded a yellow, sickly light, was completely covered up by smog. Yet the sky did not clear. The smog would not lift. \n"," \n"," That ’ s when we realized it was no longer a joke. The product was no longer sold in isolated cans anymore. It was sold in huge 4L jugs, even though that was not nearly enough. The government declared martial law. The only vehicles allowed on the road now transported the product, HA! They sold them at exorbitant prices, but it wasn ’ t entirely their fault. There was so little of it, and so many people. \n"," \n"," Out of hopelessness I turned to my safe. My apartment, new only several years ago, had walls blackened from dirt. I coughed, creating an explosion of dust, setting off a chain reaction. I finally calmed down a half minute later, and unlocked the metal box. \n"," \n"," The lock finally ticked open between my fumbling fingers. I stared into the box like a starving man. The interior of the box was filled to the brim with metal containers. The same ones I had purchased a dozen years ago. \n"," \n"," Canned air. \n","\n","\n","\n","\n"," Generated Sequence 1 \n","=====================================\n","\n","[ WP ] `` I'm sorry, but the thing you were looking for is sold out. ''  For obvious reasons, I keep turning the box over until it all burns. As usual, the instructions for this box have been published in the zine. This is the name I used, but the actual text is in Danish, and the packaging in Danish is still there. No photocopying, no no noing, no no. If you do a google search, you will find a good amount of pictures of all the problems I've discussed here.  What I like to do is the typical alternative that I have done, except that I'm taking pictures of the CPU, and not a test, so I'll keep the pictures for this day. I am also posting one photo from the console box which I have attached to my screen. I'd like to display one of the problems, and to include it into the explanation that follows, so if you think I'm wrong, please email me. All pictures are from the box and are not from the whole thing. If you think you're being either unreasonable or not on board, please let me know. 3. In order to post the picture on the online forum, you must first find the box and obtain the scan software. Next, you can download the software from http://softwarehacking.com/. Then you can browse the site for the game, scan the X drive in the zine, copy the picture, and let it rip your image. I'm not sure if the copy-paste takes anywhere less than a minute. I do have to remember to first add the dot to the end of the image to save it. I have to tell the user which image to add to save, and who to remove. This is the same process you go through when you upload a file to YouTube. Here is a copy of the picture for the console, and the picture for the X drive, as well as a bit more information on the scan software. The picture will be taken on the machine. I am using the motherboard. The problem with this picture is that it has a CPU attached to it, so if you don't get the copy-paste, you need to follow this step in order to get a good picture. After you have a good picture, you can download the image and then it will be available on YouTube. I would like to suggest that you please download the picture of the right side of the box and keep on taking pictures of the lef\n","\n","\n"," Generated Sequence 2 \n","=====================================\n","\n","[ WP ] `` I'm sorry, but the thing you were looking for is sold out. ''  \"Do you think this is what they'd call it? ''  \" The guy is selling it in his home.\n","The nice thing about this is that we don't have to go through every item in our system.  If you want to open up a stock, you just need to open a mail order for the real deal, and that's what we do.  On this particular machine I opened a 25% cask, and then the other 20% that we're going to turn to is 1.8% oak.  Then the rest is alfred! And then we're going to put an 80 year old linen guitar in it, which was kind of a joke to me, and then we have to turn that to 3% pine needles for our video boards and our soundboards.  Then we're going to turn to other types of equipment that we'll give back to you, as well. Then we're going to hand over the stock and give you a digital file on our printers, where you can go to the rest of your purchase with the little things you want. We're going to provide you with this information for a month, then we'll turn it over to you for a full month.  It's nice that this is all actually manufactured within a short time, but a few things go out the window when we can't do it. You're going to get the barber in less than a week, and the other part of the company has to move the camera.  They've got to repair those parts as quickly as possible, and then they have to retool the equipment and hand it over to us. We're not going to do that on a regular basis. We're going to keep making progress, which is really very important.  We're going to pay for those improvements, and then we're going to turn that over to you in the end.  You can't send it out as quickly as you want, because you won't be able to fix it. So they'll be able to have your changes in a timely fashion.  We'll move these machines back into the same place where they first came, and then we're going to deliver to you.\n","PST - 5 of 7  I love this company. They make guitar-board and acoustic gear for the guitarists that love hearing the sound of thei\n","\n","\n"," Generated Sequence 3 \n","=====================================\n","\n","[ WP ] `` I'm sorry, but the thing you were looking for is sold out. ''  On that subject, I guess you'll find this problem if you go into any department of the Department of Justice. So far as I know, the Justice Department doesn't have any records on this issue. I also believe there is something of an open-door policy with regard to military contractors. You can do your job, but you can't do it yourself. So if you don't have any records, you could potentially be charged with stealing business secrets or claiming you were on the payroll of someone else. And, again, that's not what's been pointed out, but I don't think it's something you'd ever do.... The practice of being open about this with anybody who is not under a subpoena is disturbing. `` But the next question is whether this is a civil act of civil disobedience. I would guess that it is, but it's the first step in the process.\n","The Office of the Government Inspector General is a division of the Department of Justice. According to its website, the OIG is dedicated to the promotion of public confidence in government and its agencies. In the past, it has represented public officials accused of civil rights violations or wrongdoing for the government. The OIG is not legally involved in any of the investigations or prosecutions brought against these officials, but they appear to be on record actively pursuing this particular whistleblower complaint. There are reports that the OIG has been using \"citizen body\" agents for federal investigations. Other than that, the OIG is part of the Justice Department's \"black box\" of civil liberties advocates. There are reports that the OIG has done the same for media freedom advocates. Recently, the OIG's Office of Civil Rights Affairs announced that it is making the National Commission on Civil Rights a top priority.\n","On this matter, I'll say this: I have no idea how many people are affected by this litigation. I assume most of you are wondering what you think of this issue. I hope it's not a big deal. The one thing I can tell you is that the OIG is a watchdog of all government agencies and they are committed to their duty of ensuring the rule of law in the United States is upheld. I don't think any of this is a lot of people's business. It's a broad, diverse collection of government agencies and the OIG is based on the values that all of us hold dear. It's clear that th\n"]}],"source":["# generate more stories from the same prompt as before fine-tuning to see the difference\n","token = \"<ENDPROMPT>\"\n","chosen = 4\n","prompt = test_data[chosen][ : test_data[chosen].find(token)]\n","story = test_data[chosen][test_data[chosen].find(token)+len(token) : ]\n","print(len(prompt))\n","generate_stories(model, tokenizer, prompt, story)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# chose 10 random prompts from the test dataset and run the generate_stories function using same logic as before \n","for i in range(10):\n","    chosen = random.sample(len(test_data), 1)\n","    prompt = test_data[chosen][ : test_data[chosen].find(token)]\n","    story = test_data[chosen][test_data[chosen].find(token)+len(token) : ]\n","    print(len(prompt))\n","    generate_stories(model, tokenizer, prompt, story)"]},{"cell_type":"markdown","metadata":{},"source":["--------------------------------------\n","\n","# Conclusion\n","\n","This lab taught us the basics of the Hugging Face Transformers library, and a specific Transformer model GPT2. This model is capable of lots of language tasks such as story generation, translation, etc. Figuring out something new and complex like this was rewarding and will provide high level experience for future tasks."]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":611893,"sourceId":1094951,"sourceType":"datasetVersion"}],"dockerImageVersionId":30615,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
